{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f2cc99-e456-439f-8fd7-5567fddb3a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mttch\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\mttch\\anaconda3\\lib\\site-packages (4.9.9)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.1.9)\n",
      "Requirement already satisfied: etils>=1.9.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.13.0)\n",
      "Requirement already satisfied: immutabledict in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.2.2)\n",
      "Requirement already satisfied: promise in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (19.0.0)\n",
      "Requirement already satisfied: simple_parsing in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.17.2)\n",
      "Requirement already satisfied: toml in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: einops in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.3.2)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
      "Requirement already satisfied: zipp in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
      "Requirement already satisfied: rich in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from dm-tree->tensorflow-datasets) (24.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from simple_parsing->tensorflow-datasets) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.72.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mttch\\anaconda3\\lib\\site-packages (from tqdm->tensorflow-datasets) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75af6302-f9bc-4cf7-a084-ca3d6a75c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#importing library for tensorflow and the default datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ea2a7a-6def-465d-bdf3-82a5a25c946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "#splitting the 'mnist' dataset in data for training and data for testing\n",
    "#as_supervised loads data as (image-lable) tuples, shuffle (useful for multi-files data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "817ebf9d-ca85-479c-bcb0-43bdb03bca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label): #simple function to normalize: the image data values range from 0:255, i want them from 0:1\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#train data pipeline: \n",
    "#.map() applies the function normalizing to every single data that goes through the \"pipeline\", like a like a loop but it doesnt block the whole data process and allows already-processed-data to continue\n",
    "#.cache() saves data in the cache so they dont need to be recomputed/reloaded every epoch\n",
    "#.shuffle() shuffle the data to avoid order-bias. IMPORTANT shuffle AFTER saving the data in the cache, otherwise every epoche will read the same cache in the same order\n",
    "#.batch divides the data in groups, making it easier for parallelism and process\n",
    "#.prefetch crates a \"buffer\" so that cpu and gpu can work in parallel to prepare and compute different batches without needing to wait each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f47712-1934-45e3-9312-201123f2ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#test data pipeline: same as train data pipeline but no need to shuffle, no need to account for order bias in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4409ea2-9461-47bc-a57a-05c0eeff0ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3593 - sparse_categorical_accuracy: 0.8993 - val_loss: 0.1839 - val_sparse_categorical_accuracy: 0.9470\n",
      "Epoch 2/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1626 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.1325 - val_sparse_categorical_accuracy: 0.9623\n",
      "Epoch 3/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1166 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.1070 - val_sparse_categorical_accuracy: 0.9685\n",
      "Epoch 4/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.0971 - val_sparse_categorical_accuracy: 0.9705\n",
      "Epoch 5/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.0871 - val_sparse_categorical_accuracy: 0.9731\n",
      "Epoch 6/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.0812 - val_sparse_categorical_accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22f825cda90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([ #applies the next functions in sequence\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), #transforms from 28x28 matrixes -> 784x1 vectorù\n",
    "  tf.keras.layers.Dense(128, activation='relu'), #maps the R^784 space of the features in a R^128 space, it forces the model to optimize the image to projects features into a latent space and discard useless informations\n",
    "    #the RELU makes the transformation non linear and allows the model to bend the space so that it can better separate the various data (in this case distinguish better the numbers)\n",
    "  tf.keras.layers.Dense(10)  #maps the R^128 space in a R^10 space and assigns a value (logit) to every possible number (proportional to the likelihood of that numbern in each image)\n",
    "])\n",
    "model.compile(#describes the rules for the learning of the model\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001), #uses ADAM with learning-rate 0.001 to modify and update the weights for the parameters\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),#defines the loss function and transforms the logits appling softmax internally\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()], #outputs the models accuracy\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
